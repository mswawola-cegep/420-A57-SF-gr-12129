{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atelier #1 - Transfert de style neuronal avec TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chaque noteobook commence par ces trois lignes; ils garantissent que toutes les modifications apportées aux modules et paquets que vous développez \"en dehors\" du Jupyter Notebook sont automatiquement rechargées lorsque modifiés. Tous les graphiques et images sont affichées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppression des warnings de manière générale\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import IPython.display\n",
    "from pathlib import Path\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import models \n",
    "from tensorflow.python.keras import losses\n",
    "from tensorflow.python.keras import layers\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "from utils import load_img, show_img, load_and_process_img, show_results, deprocess_img, compute_grads, get_feature_representations, gram_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quelques paramètres d'affichage...\n",
    "mpl.rcParams['figure.figsize'] = (12,12)\n",
    "mpl.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Vérification de la version de TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La version de TensorFlow (GPU) utilisée pour cet exercice doit être la `1.14.0`. L'installation peut-être effectué à l'aide de l'utilitaire `pip`:\n",
    "\n",
    "`pip install tensorflow-gpu==1.14.0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Vérification de la version de cuDNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /usr/include/cudnn.h | grep CUDNN_MAJOR -A 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Chemins vers les images de contenu et de style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Placez vos images dans le répertoire `images`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTENT = Path('images/will.jpg')\n",
    "STYLE = Path('images/joconde.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les images sélectionnées pour le transfert de style neuronal sont:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = load_img(CONTENT).astype('uint8')\n",
    "style = load_img(STYLE)\n",
    "plt.subplot(1, 2, 1)\n",
    "show_img(content, 'Image de contenu')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "show_img(style, 'Image de style')\n",
    "_ = plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Activation du mode d'exécution avide (Eager execution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'exécution avide (**Eager execution**) de TensorFlow est un environnement de programmation impératif évaluant les opérations immédiatement, sans construction de graphes: les opérations retournent des valeurs évaluées au lieu de construire un graphe de calcul à exécuter plus tard. Ceci facilite grandement la manipulation des modèles TensorFlow et de débogage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Définition du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La couche de contenu (feature maps)\n",
    "content_layers = ['block5_conv2'] \n",
    "\n",
    "# Les couches de style\n",
    "style_layers = ['block1_conv1',\n",
    "                'block2_conv1',\n",
    "                'block3_conv1', \n",
    "                'block4_conv1', \n",
    "                'block5_conv1'\n",
    "               ]\n",
    "\n",
    "num_content_layers = len(content_layers)\n",
    "num_style_layers = len(style_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En vous basant sur la documentation de [Keras](https://keras.io/applications/), compléter la fonction ci-dessous en utlisant un modèle pré-entraîné de type VGG19. La fonction à utiliser est la suivante:\n",
    "\n",
    "`keras.applications.vgg19.VGG19(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)`\n",
    "* Les deux couches pleinement connectées (FC, fully-connected) et la couche de sortie Softmax ne devront pas être inclues\n",
    "* Les poids à utiliser doivent correspondre à VGG19 pré-entraîné sur ImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Architecture de VGG19](static/VGG19.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    \n",
    "    vgg = tf.keras.applications.vgg19.VGG19(include_top=False, weights='imagenet')\n",
    "    vgg.trainable = False\n",
    "    \n",
    "    # Couches de sortie correspondant aux couches de style et de contenu\n",
    "    style_outputs = [vgg.get_layer(name).output for name in style_layers]\n",
    "    content_outputs = [vgg.get_layer(name).output for name in content_layers]\n",
    "    model_outputs = style_outputs + content_outputs\n",
    "    \n",
    "    # Construction du modèle \n",
    "    return models.Model(vgg.input, model_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Transfert de style neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres\n",
    "lr = 5\n",
    "beta1 = 0.99\n",
    "epsilon = 1e-1\n",
    "num_iterations = 1000\n",
    "content_weight = 1e3\n",
    "style_weight = 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_style_transfer(content_path, style_path,\n",
    "                       num_iterations=num_iterations, content_weight=content_weight, style_weight=style_weight): \n",
    "    \n",
    "    # Le transfert de style n'implique pas d'entraînement à proprement parler\n",
    "    model = get_model() \n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "  \n",
    "    # Pour obtenir les représentations de contenu (feature) et de style à partir des couches cachées sélectionnées \n",
    "    style_features, content_features = get_feature_representations(model, content_path, style_path, num_style_layers)\n",
    "    gram_style_features = [gram_matrix(style_feature) for style_feature in style_features]\n",
    "  \n",
    "    # Image initiale\n",
    "    init_image = load_and_process_img(content_path)\n",
    "    init_image = tf.Variable(init_image, dtype=tf.float32)\n",
    "    \n",
    "    # Creation de l'optimiseur\n",
    "    opt = tf.train.AdamOptimizer(learning_rate=lr, beta1=beta1, epsilon=epsilon)\n",
    "\n",
    "    # Sauvegarde du meilleur résultat\n",
    "    best_loss, best_img = float('inf'), None\n",
    "  \n",
    "    # Configuration \n",
    "    loss_weights = (style_weight, content_weight)\n",
    "    cfg = {\n",
    "      'model': model,\n",
    "      'loss_weights': loss_weights,\n",
    "      'init_image': init_image,\n",
    "      'gram_style_features': gram_style_features,\n",
    "      'content_features': content_features,\n",
    "      'num_style_layers': num_style_layers,\n",
    "      'num_content_layers': num_content_layers\n",
    "    }\n",
    "    \n",
    "    # Transfer de style avec affichage\n",
    "    iter_count = 1\n",
    "    num_rows = 2\n",
    "    num_cols = 5\n",
    "    display_interval = num_iterations/(num_rows*num_cols)\n",
    "    start_time = time.time()\n",
    "    global_start = time.time()\n",
    "  \n",
    "    norm_means = np.array([103.939, 116.779, 123.68])\n",
    "    min_vals = -norm_means\n",
    "    max_vals = 255 - norm_means   \n",
    "  \n",
    "    imgs = []\n",
    "    for i in range(num_iterations):\n",
    "        grads, all_loss = compute_grads(cfg)\n",
    "        loss, style_score, content_score = all_loss\n",
    "        opt.apply_gradients([(grads, init_image)])\n",
    "        clipped = tf.clip_by_value(init_image, min_vals, max_vals)\n",
    "        init_image.assign(clipped)\n",
    "        end_time = time.time() \n",
    "    \n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_img = deprocess_img(init_image.numpy())\n",
    "\n",
    "        if i % display_interval== 0:\n",
    "             start_time = time.time()\n",
    "      \n",
    "        plot_img = init_image.numpy()\n",
    "        plot_img = deprocess_img(plot_img)\n",
    "        imgs.append(plot_img)\n",
    "        IPython.display.clear_output(wait=True)\n",
    "        IPython.display.display_png(Image.fromarray(plot_img))\n",
    "        print('Iteration: {}'.format(i))        \n",
    "        print('Total loss: {:.4e}, ' \n",
    "            'style loss: {:.4e}, '\n",
    "            'content loss: {:.4e}, '\n",
    "            'time: {:.4f}s'.format(loss, style_score, content_score, time.time() - start_time))\n",
    "    \n",
    "    print('Total time: {:.4f}s'.format(time.time() - global_start))\n",
    "    \n",
    "      \n",
    "    return best_img, best_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_img, best_loss = run_style_transfer(CONTENT, STYLE, num_iterations=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_results(best_img, CONTENT, STYLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Références"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [A Neural Algorithm of Artistic Style](https://arxiv.org/abs/1508.06576)\n",
    "* [Neural Style Transfer: Creating Art with Deep Learning using tf.keras and eager execution](https://medium.com/tensorflow/neural-style-transfer-creating-art-with-deep-learning-using-tf-keras-and-eager-execution-7d541ac31398)\n",
    "* [Transfer Learning in Tensorflow (VGG19 on CIFAR-10): Part 1](https://towardsdatascience.com/transfer-learning-in-tensorflow-9e4f7eae3bb4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "C8TP1-TensorFlow",
   "language": "python",
   "name": "c8tp1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
